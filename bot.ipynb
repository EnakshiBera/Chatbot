{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Enakshi\n",
      "[nltk_data]     Bera\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Enakshi\n",
      "[nltk_data]     Bera\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import string # to process standard python strings\n",
    "\n",
    "m=open('modules python.txt','r',errors = 'ignore')\n",
    "f=open('Answers python.txt','r',errors = 'ignore')\n",
    "\n",
    "raw=f.read() #read the f file --> nlp python answer finals.txt\n",
    "raw_one=m.read() #read the m file --> modules pythons.txt\n",
    "raw=raw.lower()# converts to lowercase\n",
    "raw_one=raw_one.lower()# converts to lowercase\n",
    "nltk.download('punkt') # first-time use only\n",
    "nltk.download('wordnet') # first-time use only\n",
    "sent_tokens = nltk.sent_tokenize(raw)# converts to list of sentences \n",
    "word_tokens = nltk.word_tokenize(raw)# converts to list of words\n",
    "sent_tokens_one = nltk.sent_tokenize(raw_one)# converts to list of sentences \n",
    "word_tokens_one = nltk.word_tokenize(raw_one)# converts to list of words\n",
    "\n",
    "\n",
    "sent_tokens[:2]\n",
    "sent_tokens_one[:2]\n",
    "\n",
    "word_tokens[:5]\n",
    "word_tokens_one[:5]\n",
    "\n",
    "lemmer = nltk.stem.WordNetLemmatizer()\n",
    "def LemTokens(tokens):\n",
    "    return [lemmer.lemmatize(token) for token in tokens]\n",
    "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
    "def LemNormalize(text):\n",
    "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))\n",
    "\n",
    "Introduce_Ans = [\"My name is PyBot.\",\"My name is PyBot you can called me pi.\",\"Im PyBot :) \",\"My name is PyBot. and my nickname is pi and i am happy to solve your queries :) \"]\n",
    "GREETING_INPUTS = (\"hello\", \"hi\",\"hiii\",\"hii\",\"hiiiii\",\"hiiii\", \"greetings\", \"sup\", \"what's up\",\"whats up\",\"hey\")\n",
    "GREETING_RESPONSES = [\"hi\", \"hey\", \"hii there\", \"hi there\", \"hello\", \"I am glad! You are talking to me\"]\n",
    "Basic_Q = (\"what is python ?\",\"what is python\",\"what is python?\",\"what is python.\")\n",
    "Basic_Ans = \"Python is a high-level, interpreted, interactive and object-oriented scripting programming language. Python is designed to be highly readable. It uses English keywords frequently where as other languages use punctuation, and it has fewer syntactical constructions than other languages.\"\n",
    "Basic_Om = (\"what is module\",\"what is module.\",\"what is module \",\"what is module ?\",\"what is module?\",\"what is module in python\",\"what is module in python.\",\"what is module in python?\",\"what is module in python ?\")\n",
    "Basic_AnsM = [\"Consider a module to be the same as a code library.\",\"A file containing a set of functions you want to include in your application.\",\"A module can define functions, classes and variables. A module can also include runnable code. Grouping related code into a module makes the code easier to understand and use.\"]\n",
    "\n",
    "\n",
    "# Checking for greetings\n",
    "def greeting(sentence):\n",
    "    \"\"\"If user's input is a greeting, return a greeting response\"\"\"\n",
    "    for word in sentence.split():\n",
    "        if word.lower() in GREETING_INPUTS:\n",
    "            return random.choice(GREETING_RESPONSES)\n",
    "\n",
    "# Checking for Basic_Q\n",
    "def basic(sentence):\n",
    "    for word in Basic_Q:\n",
    "        if sentence.lower() == word:\n",
    "            return Basic_Ans\n",
    "\n",
    "# Checking for Basic_QM\n",
    "def basicM(sentence):\n",
    "    \"\"\"If user's input is a greeting, return a greeting response\"\"\"\n",
    "    for word in Basic_Om:\n",
    "        if sentence.lower() == word:\n",
    "            return random.choice(Basic_AnsM)\n",
    "        \n",
    "# Checking for Introduce\n",
    "def IntroduceMe(sentence):\n",
    "    return random.choice(Introduce_Ans)\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "# Generating response\n",
    "def response(user_response):\n",
    "    robo_response=''\n",
    "    sent_tokens.append(user_response)\n",
    "    TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')\n",
    "    tfidf = TfidfVec.fit_transform(sent_tokens)\n",
    "    vals = cosine_similarity(tfidf[-1], tfidf)\n",
    "    idx=vals.argsort()[0][-2]\n",
    "    flat = vals.flatten()\n",
    "    flat.sort()\n",
    "    req_tfidf = flat[-2]\n",
    "    if(req_tfidf==0):\n",
    "        robo_response=robo_response+\"I am sorry! Right now I don't know the answer. Please check google to find this answer\"\n",
    "        return robo_response\n",
    "    else:\n",
    "        robo_response = robo_response+sent_tokens[idx]\n",
    "        return robo_response\n",
    "      \n",
    "# Generating response\n",
    "def responseone(user_response):\n",
    "    robo_response=''\n",
    "    sent_tokensone.append(user_response)\n",
    "    TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')\n",
    "    tfidf = TfidfVec.fit_transform(sent_tokensone)\n",
    "    vals = cosine_similarity(tfidf[-1], tfidf)\n",
    "    idx=vals.argsort()[0][-2]\n",
    "    flat = vals.flatten()\n",
    "    flat.sort()\n",
    "    req_tfidf = flat[-2]\n",
    "    if(req_tfidf==0):\n",
    "        robo_response=robo_response+\"I am sorry! Right now I don't know the answer. Please check google to find this answer\"\n",
    "        return robo_response\n",
    "    else:\n",
    "        robo_response = robo_response+sent_tokensone[idx]\n",
    "        return robo_response\n",
    "\n",
    "def check(string, sub_str): \n",
    "    if (string.find(sub_str) == -1): \n",
    "        print(\"NO\") \n",
    "    else: \n",
    "        print(\"YES\") \n",
    "\n",
    "def chat(user_response):\n",
    "    user_response=user_response.lower()\n",
    "    keyword = \" module \"\n",
    "    keywordone = \" module\"\n",
    "    keywordsecond = \"module \"\n",
    "    \n",
    "    if(user_response!='bye' or user_response!='see ya!' or user_response!='see ya'):\n",
    "        if(user_response=='thanks' or user_response=='thank you' ):\n",
    "            flag=False\n",
    "            return \"You are welcome..\"\n",
    "        elif(user_response=='who are you?' or user_response=='who are you' or user_response=='what are you?' or user_response=='what are you'):\n",
    "            flag=False\n",
    "            return \"I am Pybot\"\n",
    "        elif(check(user_response,'are you better')=='YES'):\n",
    "            flag=False\n",
    "            return \"I don't think so\"\n",
    "        elif(user_response=='what can you do?' or user_response=='what do you do?' or user_response=='what can you do' or user_response=='what do you do'):\n",
    "            flag=False\n",
    "            return \"You can ask me questions about python\"\n",
    "        elif(user_response=='where can I learn python?' or user_response=='where can I learn python' or user_response=='how can I learn python?') or user_response=='how can I learn python':\n",
    "            flag=False\n",
    "            return \"https://www.geeksforgeeks.org/python-programming-language/\"\n",
    "        elif(basicM(user_response)!=None):\n",
    "            return basicM(user_response)\n",
    "        else:\n",
    "            if(user_response.find(keyword) != -1 or user_response.find(keywordone) != -1 or user_response.find(keywordsecond) != -1):\n",
    "                return responseone(user_response)\n",
    "                sent_tokensone.remove(user_response)\n",
    "            elif(greeting(user_response)!=None):\n",
    "                return greeting(user_response)\n",
    "            elif(user_response.find(\"your name\") != -1 or user_response.find(\" your name\") != -1 or user_response.find(\"your name \") != -1 or user_response.find(\" your name \") != -1):\n",
    "                return IntroduceMe(user_response)\n",
    "            elif(basic(user_response)!=None):\n",
    "                return basic(user_response)\n",
    "            else:\n",
    "                return response(user_response)\n",
    "                sent_tokens.remove(user_response)\n",
    "                \n",
    "    else:\n",
    "        flag=False\n",
    "        return \"Bye! take care..\"\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
